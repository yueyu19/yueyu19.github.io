---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a postdoc at the Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin. My advisor is [Professor Ufuk Topcu](https://www.ae.utexas.edu/people/faculty/faculty-directory/topcu). I obtained my PhD degree from Univsersity of Washington. My PhD advisor is [Professor Behcet Acikmese](https://www.aa.washington.edu/facultyfinder/behcet-acikmese). 



# Research interests

My research aims to build autonomous systems that adapt fast, counter adversaries, and resolve conflicts. My research develops theoretical and computational methods by combining tools from various fields, including optimization, control, game theory, and machine learning. 

## Optimizing trajectories within a split second

Fast trajectory optimization is the key to for autonomous systems to operate in fast-changing environments. My research help develop some of the fastest mathematical methods and numerical software for solving constrained convex trajectory optimization problems, reducing minutes of computation time to a split second. 

<p align = "center">
<iframe width="560" height="315" src="https://www.youtube.com/watch?v=4IBCsSQc8c8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

## Poisoning attacks against data-driven control

Data enable us to control systems with unknown dynamics. But How vunlnerable is our data-driven controller against malicious attacks aginst our data? My research identifies and evaluates the threats of poisoning attacks aginst data-driven controlers. 

<p align = "center">
<iframe width="560" height="315" src="https://youtu.be/4IBCsSQc8c8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

## Incentive design in noncooperative games

How can we design the incentive mechanisms that encourage rival agents to stop working at cross purposes? My research answers this question by leveraging tools from game theory and nonconvex optimization.

<p align = "center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/EvtPp_DWqgU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>


